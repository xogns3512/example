{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##All General Import Statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "%matplotlib inline\n",
    "import random\n",
    "from matplotlib import pyplot\n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly Detection Algorithms: Isolation Forest vs the Rest\n",
    "This notebook shows a simplified implementation of the algorithm Isolation Forest and compares its Scikit-learn implementation with other popular anomaly detection algorithms. (KMeans, Local Outlier Factor, One-Class SVM)\n",
    "\n",
    "In a real world scenario, an unsupervised model is used primarily as a seed to create labelled data unless risk rules based on domain knowledge can be formulated for the problem. For example, if the problem is to identify anomalies in network traffic metrics such as time between logins and distance between origins can be used to formulate a risk rule. Anomalous logins obtained by applying this rule must then be audited to come up with their true labels. On the other hand take the case of identifying the probability of an employee committing securities fraud. Here the behavioral data that the organization captures is very high dimensional and the relationship between the data points is complex. Hence without indepth domain knowledge, formulating risk rules is difficult. This combined with issues such as confidentiality makes it very hard to validate these risk rules.\n",
    "\n",
    "This is where unsupervised learning shines. With very little domain knowledge, a simple unsupervised algorithm can be used to create a list of anomalies which can then be fed into an auditing process which then generates the true labels. Over time when enough data labels are created, the unsupervised problem can be reformulated as a supervised ML problem.\n",
    "\n",
    "Since this notebook aims to compare various unsupervised algorithms with each other their actual performance needs to be validated. For this I use a labelled dataset. But the algorithms do not see the labels while training. The labels are only used to compare the model predictions to the actual values and to create performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
